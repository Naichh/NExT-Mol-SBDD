{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c52188c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/share/liuzhiyuan/envs/esm3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "库导入成功！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "#import py3Dmol\n",
    "import warnings\n",
    "from pocket_embed_new import process_pocket,_handle_alt_loc_df,standardize_pdb\n",
    "# 忽略pandas读取固定宽度文件时的性能警告\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "import os\n",
    "import torch\n",
    "import tempfile\n",
    "import argparse\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import io\n",
    "import warnings\n",
    "\n",
    "# 忽略pandas读取固定宽度文件时的性能警告\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Assuming ESM-3 and other dependencies are installed\n",
    "from esm.models.esm3 import ESM3\n",
    "from esm.sdk.api import ESMProtein, LogitsConfig\n",
    "\n",
    "print(\"库导入成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7b44f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bfd3352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功找到文件：3wz8_A_rec_5hct_61p_lig_tt_min_0_pocket10.pdb\n",
      "[*] Loading ESM-3 model... (this may take a moment)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 22 files: 100%|██████████| 22/22 [00:00<00:00, 4032.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Use bfloat16 for faster inference and less memory usage if available\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mESM3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mesm3-sm-open-v1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[*] Model loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# --- Improvement 2: Discover all files using your index.pkl ---\u001b[39;00m\n",
      "File \u001b[0;32m/data/share/liuzhiyuan/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:1369\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1367\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/share/liuzhiyuan/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:928\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 928\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/data/share/liuzhiyuan/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:928\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 928\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/data/share/liuzhiyuan/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:955\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 955\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "File \u001b[0;32m/data/share/liuzhiyuan/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:1355\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1349\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1350\u001b[0m             device,\n\u001b[1;32m   1351\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1352\u001b[0m             non_blocking,\n\u001b[1;32m   1353\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1354\u001b[0m         )\n\u001b[0;32m-> 1355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1361\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/data/share/liuzhiyuan/envs/esm3/lib/python3.10/site-packages/torch/cuda/__init__.py:412\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    411\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 412\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    416\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# --- 请修改为您的文件路径 ---\n",
    "# 假设您已将test_set解压到data目录下\n",
    "pdb_path = Path(\"/mnt/rna01/liuzhiyuan/zyliu/nai/NExT-Mol/data/cross_docked_new/crossdocked_pocket/CARP_CRYPA_90_419_catalytic_0/3wz8_A_rec_5hct_61p_lig_tt_min_0_pocket10.pdb\")\n",
    "\n",
    "if not pdb_path.exists():\n",
    "    print(f\"错误：文件未找到！请检查路径：{pdb_path}\")\n",
    "else:\n",
    "    print(f\"成功找到文件：{pdb_path.name}\")\n",
    "\n",
    "\n",
    "# --- Improvement 1: Load the model ONCE ---\n",
    "print(\"[*] Loading ESM-3 model... (this may take a moment)\")\n",
    "device = torch.device(1)\n",
    "# Use bfloat16 for faster inference and less memory usage if available\n",
    "model = ESM3.from_pretrained(\"esm3-sm-open-v1\").to(device).eval()\n",
    "print(\"[*] Model loaded successfully.\")\n",
    "\n",
    "# --- Improvement 2: Discover all files using your index.pkl ---\n",
    "\n",
    "output_path ='/mnt/rna01/liuzhiyuan/zyliu/nai/NExT-Mol/test_scripts'\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "embedding = process_pocket(str(pdb_path), model, device)\n",
    "if embedding is not None:\n",
    "        torch.save(embedding, output_path)\n",
    "\n",
    "\n",
    "print(\"[*] All pockets processed successfully.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e73f821a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 文件记录类型统计 ---\n",
      "HEADER    : 1 行\n",
      "COMPND    : 1 行\n",
      "ATOM      : 205 行\n",
      "END       : 1 行\n",
      "\n",
      "[结论] -> 文件中不含 HETATM 记录。\n"
     ]
    }
   ],
   "source": [
    "record_counts = {}\n",
    "with open(pdb_path, 'r') as f:\n",
    "    for line in f:\n",
    "        record_type = line[0:6].strip()\n",
    "        if record_type:\n",
    "            record_counts[record_type] = record_counts.get(record_type, 0) + 1\n",
    "\n",
    "print(\"--- 文件记录类型统计 ---\")\n",
    "for record, count in record_counts.items():\n",
    "    print(f\"{record:<10s}: {count} 行\")\n",
    "\n",
    "if 'HETATM' in record_counts:\n",
    "    print(\"\\n[结论] -> 文件中包含 HETATM 记录，需要清理！\")\n",
    "else:\n",
    "    print(\"\\n[结论] -> 文件中不含 HETATM 记录。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/rna01/liuzhiyuan/zyliu/nai/NExT-Mol/data/cross_docked_new/crossdocked_pocket/ALDR_HUMAN_1_316_0/4qr6_A_rec_4qbx_30l_lig_tt_min_0_pocket10.pdb  '",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecord_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124matom_serial\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124matom_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malt_loc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchain_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres_seq\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi_code\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moccupancy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp_factor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melement\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcharge\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 读取PDB文件\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m pdb_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_fwf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolspecs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolspecs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 过滤掉空的或非原子记录的行\u001b[39;00m\n\u001b[1;32m     12\u001b[0m pdb_df \u001b[38;5;241m=\u001b[39m pdb_df[pdb_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecord_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATOM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHETATM\u001b[39m\u001b[38;5;124m'\u001b[39m])]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/data/share/liuzhiyuan/envs/nextmol/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/share/liuzhiyuan/envs/nextmol/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1385\u001b[0m, in \u001b[0;36mread_fwf\u001b[0;34m(filepath_or_buffer, colspecs, widths, infer_nrows, **kwds)\u001b[0m\n\u001b[1;32m   1383\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfer_nrows\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m infer_nrows\n\u001b[1;32m   1384\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython-fwf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/share/liuzhiyuan/envs/nextmol/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/data/share/liuzhiyuan/envs/nextmol/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/share/liuzhiyuan/envs/nextmol/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/data/share/liuzhiyuan/envs/nextmol/lib/python3.8/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/rna01/liuzhiyuan/zyliu/nai/NExT-Mol/data/cross_docked_new/crossdocked_pocket/ALDR_HUMAN_1_316_0/4qr6_A_rec_4qbx_30l_lig_tt_min_0_pocket10.pdb  '"
     ]
    }
   ],
   "source": [
    "# PDB ATOM/HETATM 记录的列定义\n",
    "# 参考: https://www.wwpdb.org/documentation/file-format-content/format33/sect9.html#ATOM\n",
    "colspecs = [(0, 6), (6, 11), (12, 16), (16, 17), (17, 20), (21, 22), (22, 26), \n",
    "            (26, 27), (30, 38), (38, 46), (46, 54), (54, 60), (60, 66), (76, 78), (78, 80)]\n",
    "names = ['record_name', 'atom_serial', 'atom_name', 'alt_loc', 'res_name', 'chain_id', \n",
    "         'res_seq', 'i_code', 'x', 'y', 'z', 'occupancy', 'temp_factor', 'element', 'charge']\n",
    "\n",
    "# 读取PDB文件\n",
    "pdb_df = pd.read_fwf(pdb_path, colspecs=colspecs, names=names, header=None)\n",
    "\n",
    "# 过滤掉空的或非原子记录的行\n",
    "pdb_df = pdb_df[pdb_df['record_name'].isin(['ATOM', 'HETATM'])].reset_index(drop=True)\n",
    "\n",
    "print(\"--- PDB文件前5行预览 ---\")\n",
    "display(pdb_df.head())\n",
    "\n",
    "print(\"\\n--- 不同残基/分子名称统计 ---\")\n",
    "# .value_counts() 会统计每个名称出现的次数\n",
    "print(pdb_df['res_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4890580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功找到主索引文件：/mnt/rna01/liuzhiyuan/zyliu/nai/NExT-Mol/data/cross_docked_new/crossdocked_pocket/index.pkl\n",
      "从索引中成功加载了 166500 个唯一的口袋文件路径。\n",
      "\n",
      "随机抽查 30 个PDB文件...\n",
      "================================================================================\n",
      "文件: CHK2_HUMAN_210_526_0/2wtd_A_rec_2cn8_dbq_lig_tt_docked_0_pocket10.pdb  -> 状态: ✅ 纯净\n",
      "文件: MDM2_HUMAN_16_114_0/5trf_D_rec_4oq3_2v8_lig_tt_docked_0_pocket10.pdb   -> 状态: ✅ 纯净\n",
      "文件: CARP_CRYPA_90_419_catalytic_0/3wz8_A_rec_5hct_61p_lig_tt_min_0_pocket10.pdb -> 状态: 🟡 发现 ALT LOC\n",
      "文件: POL_HV1B1_826_919_0/5fdl_A_rec_5vqs_9kd_lig_tt_min_0_pocket10.pdb      -> 状态: ✅ 纯净\n",
      "文件: EED_HUMAN_76_441_0/5h17_A_rec_5u5k_7vy_lig_tt_docked_0_pocket10.pdb    -> 状态: ✅ 纯净\n",
      "文件: KAPCA_HUMAN_8_351_0/2uzt_A_rec_3zo2_15i_lig_tt_docked_1_pocket10.pdb   -> 状态: ✅ 纯净\n",
      "文件: HYES_HUMAN_230_551_0/3wk6_A_rec_5akl_6n8_lig_tt_min_0_pocket10.pdb     -> 状态: ✅ 纯净\n",
      "文件: ADH1E_HORSE_2_375_0/1axg_A_rec_2jhg_nad_lig_tt_docked_0_pocket10.pdb   -> 状态: ✅ 纯净\n",
      "文件: BRD9_HUMAN_133_241_0/4uiu_A_rec_5igm_bmf_lig_tt_docked_1_pocket10.pdb  -> 状态: ✅ 纯净\n",
      "文件: PIM1_HUMAN_121_402_0/5toe_A_rec_5tel_7aj_lig_tt_min_0_pocket10.pdb     -> 状态: ✅ 纯净\n",
      "文件: BRD4_HUMAN_42_168_0/4nue_A_rec_5kdh_6rx_lig_tt_min_0_pocket10.pdb      -> 状态: ✅ 纯净\n",
      "文件: DDR1_HUMAN_598_913_0/5fdx_B_rec_5fdx_5x1_lig_tt_docked_0_pocket10.pdb  -> 状态: ✅ 纯净\n",
      "文件: TNKS2_HUMAN_948_1162_0/4uvw_A_rec_5dcz_59b_lig_tt_docked_0_pocket10.pdb -> 状态: ✅ 纯净\n",
      "文件: KDM4A_HUMAN_1_358_0/2p5b_A_rec_3njy_8xq_lig_tt_min_0_pocket10.pdb      -> 状态: ✅ 纯净\n",
      "文件: PPARG_HUMAN_229_505_0/4hee_X_rec_5hzc_65w_lig_tt_min_0_pocket10.pdb    -> 状态: ✅ 纯净\n",
      "文件: CAH2_HUMAN_2_260_0/1i91_A_rec_1bnm_al8_lig_tt_docked_3_pocket10.pdb    -> 状态: ✅ 纯净\n",
      "文件: GSTK1_HUMAN_1_226_0/3rpn_D_rec_3rpn_gtx_lig_tt_min_0_pocket10.pdb      -> 状态: ✅ 纯净\n",
      "文件: KTHY_STAAM_1_205_0/4qgg_A_rec_4hlc_t05_lig_tt_docked_1_pocket10.pdb    -> 状态: ✅ 纯净\n",
      "文件: ALDR_HUMAN_1_316_0/4qr6_A_rec_4qbx_30l_lig_tt_min_0_pocket10.pdb       -> 状态: 🟡 发现 ALT LOC\n",
      "文件: JAK2_HUMAN_834_1132_0/4c61_B_rec_4gfm_0x2_lig_tt_min_0_pocket10.pdb    -> 状态: ✅ 纯净\n",
      "文件: SDIS_COMTE_1_125_0/3ov4_A_rec_5ugi_equ_lig_tt_docked_1_pocket10.pdb    -> 状态: 🟡 发现 ALT LOC\n",
      "文件: ETHR_MYCTU_1_216_0/5ipa_A_rec_5ipa_6c8_lig_tt_docked_1_pocket10.pdb    -> 状态: ✅ 纯净\n",
      "文件: CBP_HUMAN_1079_1197_0/3p1d_B_rec_5mqk_qpr_lig_tt_docked_0_pocket10.pdb -> 状态: 🟡 发现 ALT LOC\n",
      "文件: PANC_MYCTU_1_301_0/1n2o_A_rec_4muj_2du_lig_tt_docked_0_pocket10.pdb    -> 状态: ✅ 纯净\n",
      "文件: CARP_CRYPA_90_419_catalytic_0/4y5k_A_rec_4y53_47b_lig_tt_min_0_pocket10.pdb -> 状态: 🟡 发现 ALT LOC\n",
      "文件: TRMD_HAEIN_2_246_0/4mcd_A_rec_4yq7_4g4_lig_tt_min_0_pocket10.pdb       -> 状态: ✅ 纯净\n",
      "文件: KAPCA_HUMAN_8_351_0/1q61_A_rec_2uw5_gvn_lig_tt_min_0_pocket10.pdb      -> 状态: ✅ 纯净\n",
      "文件: APHA_ECOLI_26_237_0/1rmq_A_rec_1rmy_dcz_lig_tt_min_0_pocket10.pdb      -> 状态: ✅ 纯净\n",
      "文件: HYES_HUMAN_230_551_0/5akh_A_rec_4y2j_49g_lig_tt_min_0_pocket10.pdb     -> 状态: 🟡 发现 ALT LOC\n",
      "文件: CSK2A_MAIZE_1_331_0/2oxd_A_rec_2oxy_k17_lig_tt_docked_9_pocket10.pdb   -> 状态: ✅ 纯净\n",
      "================================================================================\n",
      "抽查完毕。\n",
      "[总结] -> 在抽查的 30 个样本中: \n",
      "  - 0 个文件包含 HETATM 记录。\n",
      "  - 6 个文件包含 ALT LOC 记录。\n",
      "  - 24 个文件两种问题都未发现。\n",
      "\n",
      "[结论] -> 数据集中存在需要处理的文件。为了保证数据一致性和模型输入的稳定性，\n",
      "         执行一个统一的、能同时处理HETATM和ALT LOC的预处理流程是必要的。\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 请设置为您的数据集根目录 ---\n",
    "dataset_root = Path(\"/mnt/rna01/liuzhiyuan/zyliu/nai/NExT-Mol/data/cross_docked_new/crossdocked_pocket\") \n",
    "\n",
    "# 1. 构建主索引文件的路径\n",
    "index_path = dataset_root / \"index.pkl\"\n",
    "\n",
    "if not index_path.exists():\n",
    "    print(f\"错误：主索引文件未找到！请检查路径：{index_path}\")\n",
    "else:\n",
    "    print(f\"成功找到主索引文件：{index_path}\")\n",
    "\n",
    "    # 2. 读取主索引文件 (index.pkl)\n",
    "    with open(index_path, 'rb') as f:\n",
    "        master_index = pickle.load(f)\n",
    "\n",
    "    # 3. 从主索引中提取所有唯一的口袋PDB文件相对路径\n",
    "    all_pocket_paths_relative = sorted(list(set([item[0] for item in master_index if item[0] is not None])))\n",
    "    \n",
    "    print(f\"从索引中成功加载了 {len(all_pocket_paths_relative)} 个唯一的口袋文件路径。\")\n",
    "\n",
    "    # 4. 随机抽样并进行检查\n",
    "    num_samples_to_check = 30 # 可以适当增加抽样数量以获得更全面的了解\n",
    "    if len(all_pocket_paths_relative) > num_samples_to_check:\n",
    "        sample_relative_paths = random.sample(all_pocket_paths_relative, num_samples_to_check)\n",
    "    else:\n",
    "        sample_relative_paths = all_pocket_paths_relative\n",
    "\n",
    "    print(f\"\\n随机抽查 {len(sample_relative_paths)} 个PDB文件...\\n\" + \"=\"*80)\n",
    "\n",
    "    # --- 新增计数器 ---\n",
    "    found_hetatm_count = 0\n",
    "    found_alt_loc_count = 0\n",
    "    clean_count = 0\n",
    "\n",
    "    for relative_path in sample_relative_paths:\n",
    "        full_pdb_path = dataset_root / relative_path\n",
    "        \n",
    "        if not full_pdb_path.exists():\n",
    "            print(f\"文件: {relative_path} -> 状态: 警告 - 文件不存在！\")\n",
    "            continue\n",
    "\n",
    "        # --- 新增标志位 ---\n",
    "        has_hetatm = False\n",
    "        has_alt_loc = False\n",
    "        \n",
    "        with open(full_pdb_path, 'r', errors='ignore') as f:\n",
    "            for line in f:\n",
    "                # 检查 HETATM\n",
    "                if line.startswith(\"HETATM\"):\n",
    "                    has_hetatm = True\n",
    "                \n",
    "                # 检查 ALT LOC (在ATOM记录的第17列，即index 16)\n",
    "                elif line.startswith(\"ATOM\") and line[16] != ' ':\n",
    "                    has_alt_loc = True\n",
    "                \n",
    "                # 如果两种情况都找到了，可以提前结束对该文件的读取\n",
    "                if has_hetatm and has_alt_loc:\n",
    "                    break\n",
    "        \n",
    "        # --- 动态生成状态报告 ---\n",
    "        statuses = []\n",
    "        if has_hetatm:\n",
    "            statuses.append(\"🔴 发现 HETATM\")\n",
    "        if has_alt_loc:\n",
    "            statuses.append(\"🟡 发现 ALT LOC\")\n",
    "        \n",
    "        if not statuses:\n",
    "            statuses.append(\"✅ 纯净\")\n",
    "            clean_count += 1\n",
    "        \n",
    "        # --- 更新计数器 ---\n",
    "        if has_hetatm: found_hetatm_count += 1\n",
    "        if has_alt_loc: found_alt_loc_count += 1\n",
    "            \n",
    "        final_status = \", \".join(statuses)\n",
    "        print(f\"文件: {relative_path:<70} -> 状态: {final_status}\")\n",
    "\n",
    "    print(\"=\"*80 + \"\\n抽查完毕。\")\n",
    "    print(f\"[总结] -> 在抽查的 {len(sample_relative_paths)} 个样本中: \")\n",
    "    print(f\"  - {found_hetatm_count} 个文件包含 HETATM 记录。\")\n",
    "    print(f\"  - {found_alt_loc_count} 个文件包含 ALT LOC 记录。\")\n",
    "    print(f\"  - {clean_count} 个文件两种问题都未发现。\")\n",
    "\n",
    "    if found_hetatm_count > 0 or found_alt_loc_count > 0:\n",
    "        print(\"\\n[结论] -> 数据集中存在需要处理的文件。为了保证数据一致性和模型输入的稳定性，\")\n",
    "        print(\"         执行一个统一的、能同时处理HETATM和ALT LOC的预处理流程是必要的。\")\n",
    "    else:\n",
    "        print(\"\\n[结论] -> 本次抽查中未发现 HETATM 或 ALT LOC 记录。您的数据集质量非常高。\")\n",
    "        print(\"         尽管如此，为了保证流程的鲁棒性，仍然推荐在处理所有文件时都运行清理函数。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
